{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1ecdd8",
   "metadata": {},
   "source": [
    "# Oversampling to create spurious relationship\n",
    "\n",
    "In general, most oversampling strategies assume some relationship between the features and the target. For example, SMOTE assumes that it can generate new samples by linearly interpolating between existing minority samples. This **creates** a relationship between the features and the target, even if there is none.\n",
    "\n",
    "This does not mean that SMOTE is bad, it just means that you have to be careful with it &mdash; and with all oversampling strategies. Some suggestions for best practice:\n",
    "\n",
    "- Know exactly what it does.\n",
    "- Check the difference that oversampling makes.\n",
    "- Consider simple strategies like fuzzing, eg Gaussian noise up-sampling, at least for comparison.\n",
    "- Only ever apply data augmentation *after* splitting out validation and test sets. Be aware that this means you have to be very careful if applying folded cross-validation, for example as part of a hyperparameter tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24410e2c",
   "metadata": {},
   "source": [
    "## Make a dataset\n",
    "\n",
    "This highly imbalanced dataset is random and contains no predictable relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50654bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# The higher these numbers, the clearer the problem.\n",
    "N = 10_000   # Number of samples.\n",
    "M = 5        # Number of features.\n",
    "\n",
    "X = rng.uniform(size=(N, M))\n",
    "y = rng.binomial(n=1, p=0.1, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004819e",
   "metadata": {},
   "source": [
    "## Fit and score a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c642cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15031c",
   "metadata": {},
   "source": [
    "Let's try a random forest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66869d01",
   "metadata": {},
   "source": [
    "Other models perform similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba77275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe9c5a",
   "metadata": {},
   "source": [
    "Looks amazing... remember how imbalanced the dataset is!\n",
    "\n",
    "The ROC-AUC will not be fooled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72d9fd",
   "metadata": {},
   "source": [
    "And the `DummyClassifier`, whose default strategy will simply pick the majority class, makes it obvious that our model is bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e11bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb90d4f",
   "metadata": {},
   "source": [
    "## Now with oversampling\n",
    "\n",
    "We will first oversample BEFORE splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71908288",
   "metadata": {},
   "source": [
    "This (binary) dataset is now balanced, so the dummy classifier scores about 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1339bb1",
   "metadata": {},
   "source": [
    "Now with a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e373de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5cac1",
   "metadata": {},
   "source": [
    "Wow! Amazing.\n",
    "\n",
    "Logistic regression behaves as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89555422",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa13c8",
   "metadata": {},
   "source": [
    "## Oversampling after split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbe1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_res, y_res)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c95e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_res, y_res)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944060e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525339c",
   "metadata": {},
   "source": [
    "This is back to the 50/50 score we saw before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60885e0",
   "metadata": {},
   "source": [
    "## Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2        # Number of features.\n",
    "\n",
    "X = rng.uniform(size=(N, M))\n",
    "y = rng.binomial(n=1, p=0.1, size=N)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(*X_res.T, c=y_res, s=5, cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50503bb4",
   "metadata": {},
   "source": [
    "## Open questions\n",
    "\n",
    "- Should you over or undersample before or after scaling? Let's check if SMOTE changes mean or stdev. E.g. see this paper and probably lots of others: https://www.sciencedirect.com/science/article/pii/S1568494622009024 and https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3648438/. Intuitively, I think it's safer to scale first, because then the scaler only gets to see real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48f87c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&copy; 2023 Matt Hall, licensed CC BY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
