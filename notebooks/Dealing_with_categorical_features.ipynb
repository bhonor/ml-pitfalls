{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79831f6",
   "metadata": {},
   "source": [
    "# Dealing with categorical features\n",
    "\n",
    "Some features are categorical.\n",
    "\n",
    "- **Ordinal** features can be scaled, but it's not necessary.\n",
    "- **Nominal** features must be encoded, eg with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# First 2 features are informative. `weights` controls class balance.\n",
    "X, y = make_classification(n_samples=10000,\n",
    "                           n_features=4, n_classes=2,\n",
    "                           n_clusters_per_class=1,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           weights=None, random_state=42)\n",
    "\n",
    "X[:, 0] = np.digitize(X[:, 0], bins=np.linspace(-4, 4, 9))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04495623",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:25, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285f0f6",
   "metadata": {},
   "source": [
    "## Train models on these datasets\n",
    "\n",
    "- What happens if I train on this scaled dataset? Presumably it's not too bad, since the variable is ordinal.\n",
    "- What if I mix the categories (i.e. make them non-ordinal) and train on that? Presumably it's bad.\n",
    "\n",
    "Train on unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a54afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68ffab",
   "metadata": {},
   "source": [
    "Now on scaled version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_sc, y_train)\n",
    "y_hat = model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31897c0f",
   "metadata": {},
   "source": [
    "It doesn't do any harm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ff66a",
   "metadata": {},
   "source": [
    "## Nominal categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ba7ed",
   "metadata": {},
   "source": [
    "Make another version where we make x_0 purely categorical, with no order.\n",
    "\n",
    "I can't think of a way of doing this in NumPy, so Pandas it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "shuf = {\n",
    "    0: 3,\n",
    "    1: 9,\n",
    "    2: 1,\n",
    "    3: 8,\n",
    "    4: 0,\n",
    "    5: 5,\n",
    "    6: 2,\n",
    "    7: 4,\n",
    "    8: 6,\n",
    "    9: 7,\n",
    "}\n",
    "\n",
    "s = pd.Series(X[:, 0])\n",
    "\n",
    "X_shuf = X.copy()\n",
    "\n",
    "X_shuf[:, 0] = s.replace(shuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22115d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuf_train, X_shuf_test, y_shuf_train, y_shuf_test = train_test_split(X_shuf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38d982",
   "metadata": {},
   "source": [
    "Now same thing but with the shuffled categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_shuf_train)\n",
    "X_shuf_train_sc = scaler.transform(X_shuf_train)\n",
    "X_shuf_test_sc = scaler.transform(X_shuf_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_shuf_train_sc, y_shuf_train)\n",
    "y_hat = model.predict(X_shuf_test_sc)\n",
    "\n",
    "print(classification_report(y_shuf_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8db9f7",
   "metadata": {},
   "source": [
    "Oh dear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b54da9",
   "metadata": {},
   "source": [
    "## And do it properly\n",
    "\n",
    "We should dummy encode these things instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_features = [1, 2, 3]\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_features = [0]\n",
    "categorical_transformer = make_pipeline(OneHotEncoder(drop='first'))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69444999",
   "metadata": {},
   "source": [
    "Now try the two datasets.\n",
    "\n",
    "First we'll check we don't harm the ordinal feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44162656",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e4133",
   "metadata": {},
   "source": [
    "And the nominal one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_shuf_train, y_shuf_train)\n",
    "y_hat = pipe.predict(X_shuf_test)\n",
    "\n",
    "print(classification_report(y_shuf_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46730959",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ebe0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&copy; 2023 Matt Hall, licensed CC BY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
